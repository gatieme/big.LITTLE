diff -Naur linux-linaro-stable-3.10.100-2016.03/arch/arm/kernel/topology.c ../big-LITTLE/GitHub/3.10/arch/arm/kernel/topology.c
--- linux-linaro-stable-3.10.100-2016.03/arch/arm/kernel/topology.c	2016-03-31 16:31:06.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/arch/arm/kernel/topology.c	2016-12-01 14:13:47.263247974 +0800
@@ -307,6 +307,15 @@
 	return false;
 }
 
+/*  arch_get_fast_and_slow_cpus( ) 去获取系统中大小核 CPU 的 index.
+ *  这里分别为大小核定义了 domain,
+ *  把小核的 CPUs 放到小核的 domain 上,大核 CPUs 放到大核 domain 上,
+ *  然后加入到全局链表 hmp_domains_list.
+ *
+ *  查询哪些 CPU 是大小核, HMP 调度器实现了两种方式,
+ *  一个是在 CONFIG 中定义,
+ *  另外一个是通过 DTS
+ *  */
 void __init arch_get_fast_and_slow_cpus(struct cpumask *fast,
 					struct cpumask *slow)
 {
@@ -319,6 +328,8 @@
 	/*
 	 * Use the config options if they are given. This helps testing
 	 * HMP scheduling on systems without a big.LITTLE architecture.
+     *
+     * 通过设置CONFIG_HMP_FAST_CPU_MASK和CONFIG_HMP_SLOW_CPU_MASK可以设置大小核信息
 	 */
 	if (strlen(CONFIG_HMP_FAST_CPU_MASK) && strlen(CONFIG_HMP_SLOW_CPU_MASK)) {
 		if (cpulist_parse(CONFIG_HMP_FAST_CPU_MASK, fast))
@@ -330,6 +341,9 @@
 
 	/*
 	 * Else, parse device tree for little cores.
+     *
+     * 从 DTS 中读取CPU, 然后判断该 CPU 是否小核,
+     * 如果是的话把该 CPU 加入 slow 的 cpumask 位图中
 	 */
 	while ((cn = of_find_node_by_type(cn, "cpu"))) {
 
@@ -349,6 +363,15 @@
 			break;
 		}
 
+        /*  判断该 从 DTS 中读取到的 CPU 是否小核,
+         *  如果是的话把该 CPU 加入 slow 小核 的 cpumask 位图中
+         *  否则的话, 把该 CPU 加入 fast 大核 的 cpumask 位图中
+         *  这里判断是否小核主要是查表 little_cores[],
+         *  ARM32 处理器中 Cortex-A7  是小核,
+         *  ARM64 处理器中 Cortex-A53 是小核.
+         *  HMP 调度器中目前只有两个调度域,即大核调度域和小核调度域,
+         *  比内核默认的负载均衡里的 CPU 拓扑关系要简单多了
+         */
 		if (is_little_cpu(cn))
 			cpumask_set_cpu(cpu, slow);
 		else
@@ -369,11 +392,25 @@
 
 struct cpumask hmp_slow_cpu_mask;
 
+/*
+ *  HMP负载均衡调度器实现了自己的CPU拓扑结构,
+ *  该函数用于初始化HMP的cpu拓扑结构
+ *
+ *  调用关系
+ *  init_sched_fair_class( )
+ *      ->hmp_cpu_mask_setup( )
+ *          ->arch_get_hmp_domains( )
+ *  */
 void __init arch_get_hmp_domains(struct list_head *hmp_domains_list)
 {
 	struct cpumask hmp_fast_cpu_mask;
 	struct hmp_domain *domain;
 
+    /*  首先 arch_get_fast_and_slow_cpus( ) 去获取系统中大小核 CPU 的 index.
+     *  这里分别为大小核定义了 domain,
+     *  把小核的 CPUs 放到小核的 domain 上,大核 CPUs 放到大核 domain 上,
+     *  然后加入到全局链表 hmp_domains_list.
+     *  */
 	arch_get_fast_and_slow_cpus(&hmp_fast_cpu_mask, &hmp_slow_cpu_mask);
 
 	/*
diff -Naur linux-linaro-stable-3.10.100-2016.03/arch/arm64/kernel/topology.c ../big-LITTLE/GitHub/3.10/arch/arm64/kernel/topology.c
--- linux-linaro-stable-3.10.100-2016.03/arch/arm64/kernel/topology.c	2016-03-31 16:31:07.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/arch/arm64/kernel/topology.c	2016-12-01 14:13:47.279240054 +0800
@@ -483,11 +483,22 @@
 
 struct cpumask hmp_slow_cpu_mask;
 
+
+/*
+ *  HMP负载均衡调度器实现了自己的CPU拓扑结构,
+ *  该函数用于初始化HMP的cpu拓扑结构
+ *
+ *  调用关系
+ *  init_sched_fair_class( )
+ *      ->hmp_cpu_mask_setup( )
+ *          ->arch_get_hmp_domains( )
+ *  */
 void __init arch_get_hmp_domains(struct list_head *hmp_domains_list)
 {
 	struct cpumask hmp_fast_cpu_mask;
 	struct hmp_domain *domain;
 
+    /*  获取大小核的 CPU MASK (hmp_hast_cpu_mask, hmp_slow_cpu_mask)    */
 	arch_get_fast_and_slow_cpus(&hmp_fast_cpu_mask, &hmp_slow_cpu_mask);
 
 	/*
diff -Naur linux-linaro-stable-3.10.100-2016.03/.gitignore ../big-LITTLE/GitHub/3.10/.gitignore
--- linux-linaro-stable-3.10.100-2016.03/.gitignore	2016-03-31 16:31:06.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/.gitignore	1970-01-01 08:00:00.000000000 +0800
@@ -1,93 +0,0 @@
-#
-# NOTE! Don't add files that are generated in specific
-# subdirectories here. Add them in the ".gitignore" file
-# in that subdirectory instead.
-#
-# NOTE! Please use 'git ls-files -i --exclude-standard'
-# command after changing this file, to see if there are
-# any tracked files which get ignored after the change.
-#
-# Normal rules
-#
-.*
-*.o
-*.o.*
-*.a
-*.s
-*.ko
-*.so
-*.so.dbg
-*.mod.c
-*.i
-*.lst
-*.symtypes
-*.order
-modules.builtin
-*.elf
-*.bin
-*.gz
-*.bz2
-*.lzma
-*.xz
-*.lzo
-*.patch
-*.gcno
-
-#
-# Top-level generic files
-#
-/tags
-/TAGS
-/linux
-/vmlinux
-/vmlinuz
-/System.map
-/Module.markers
-/Module.symvers
-
-#
-# Debian directory (make deb-pkg)
-#
-/debian/
-
-#
-# git files that we don't want to ignore even it they are dot-files
-#
-!.gitignore
-!.mailmap
-
-#
-# Generated include files
-#
-include/config
-include/generated
-arch/*/include/generated
-
-# stgit generated dirs
-patches-*
-
-# quilt's files
-patches
-series
-
-# cscope files
-cscope.*
-ncscope.*
-
-# gnu global files
-GPATH
-GRTAGS
-GSYMS
-GTAGS
-
-*.orig
-*~
-\#*#
-
-#
-# Leavings from module signing
-#
-extra_certificates
-signing_key.priv
-signing_key.x509
-x509.genkey
diff -Naur linux-linaro-stable-3.10.100-2016.03/include/linux/sched.h ../big-LITTLE/GitHub/3.10/include/linux/sched.h
--- linux-linaro-stable-3.10.100-2016.03/include/linux/sched.h	2016-03-31 16:31:10.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/include/linux/sched.h	2016-11-30 16:24:43.801858283 +0800
@@ -892,10 +892,18 @@
 bool cpus_share_cache(int this_cpu, int that_cpu);
 
 #ifdef CONFIG_SCHED_HMP
+/*  HMP 调度器重新定义了 domain 的实现,
+ *  定义了 struct hmp_domain 数据结构(include/linux/sched.h)
+ *  该结构比较简单, cpus 和 possible_cpus 两个 cpumask 变量以及一个链表节点.
+ *  hmp_cpu_domain 是定义为 pre-CPU 变量,
+ *  即每个 CPU 有一个 struct hmp_domain 数据结构,
+ *
+ *  另外还定义了一个全局的链表 hmp_domains
+ *  */
 struct hmp_domain {
-	struct cpumask cpus;
-	struct cpumask possible_cpus;
-	struct list_head hmp_domains;
+	struct cpumask cpus;            /*  当前可运行 CPU 的 mask 标志         */
+	struct cpumask possible_cpus;   /*  所有可以运行的 CPU 的 mask 标志     */
+	struct list_head hmp_domains;   /*  链表指针域                          */
 };
 #endif /* CONFIG_SCHED_HMP */
 #else /* CONFIG_SMP */
@@ -934,6 +942,12 @@
 	unsigned long weight, inv_weight;
 };
 
+/*  HMP 调度器同样使用内核中 Per-entity 的负载计算方法,
+ *  另外它还在 sched_avg 中定义了额外的两个负载变量 load_avg_ratio 和 usage_avg_sum
+ *  load_avg_ratio 和内核中 load_avg_contrib 计算方法
+ *  sa.load_avg_ratio = (sa.sunable_sum * NICE_0_LOAD) / sa.runable_period
+ *  类似,但是它没有乘以调度实体的实际权重,而是用 nice 为 0 的权重,
+ *  因此它是进程可运行时间的一个比率  */
 struct sched_avg {
 	/*
 	 * These sums represent an infinite geometric series and so are bound
@@ -944,18 +958,27 @@
 	u64 last_runnable_update;
 	s64 decay_count;
 	unsigned long load_avg_contrib;
-	unsigned long load_avg_ratio;
+	unsigned long load_avg_ratio;       /*  进程可运行时间的一个比率                */
 #ifdef CONFIG_SCHED_HMP
-	u64 hmp_last_up_migration;
-	u64 hmp_last_down_migration;
+	u64 hmp_last_up_migration;          /*  记录当前进程调度实体上次向上迁移的时间  */
+	u64 hmp_last_down_migration;        /*  记录当前进程调度实体上次向下迁移的时间  */
 #endif
-	u32 usage_avg_sum;
+	u32 usage_avg_sum;                  /*  进程处于运行状态的负载                  */
 };
 
 #ifdef CONFIG_SCHED_HMP
 /*
  * We want to avoid boosting any processes forked from init (PID 1)
  * and kthreadd (assumed to be PID 2).
+ *
+ * 当 HMP 负载调度器处理新创建的进程时
+ * 为了避免处理 init(PID 1) 和 kthreadd(PID 2) 直接派生的进程
+ * 因此跳过此类进程的处理
+ *
+ * 调用关系
+ * int cpu = p->sched_class->select_task_rq(p, sd_flags, wake_flags);
+ *  ->  select_task_rq_fair( )
+ *      ->  hmp_task_should_forkboost( )
  */
 #define hmp_task_should_forkboost(task) ((task->parent && task->parent->pid > 2))
 #endif
diff -Naur linux-linaro-stable-3.10.100-2016.03/kernel/sched/fair.c ../big-LITTLE/GitHub/3.10/kernel/sched/fair.c
--- linux-linaro-stable-3.10.100-2016.03/kernel/sched/fair.c	2016-03-31 16:31:10.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/kernel/sched/fair.c	2016-12-01 14:55:43.232868139 +0800
@@ -33,13 +33,13 @@
 #include <trace/events/sched.h>
 #include <linux/sysfs.h>
 #include <linux/vmalloc.h>
-#ifdef CONFIG_HMP_FREQUENCY_INVARIANT_SCALE
+#ifdef CONFIG_HMP_FREQUENCY_INVARIANT_SCALE     /*  HMP 负载调度器需要DVFS调频支持   */
 /* Include cpufreq header to add a notifier so that cpu frequency
  * scaling can track the current CPU frequency
  */
 #include <linux/cpufreq.h>
 #endif /* CONFIG_HMP_FREQUENCY_INVARIANT_SCALE */
-#ifdef CONFIG_SCHED_HMP
+#ifdef CONFIG_SCHED_HMP                         /*  HMP 负载调度器需要 cpuidle 和cpuhotplug 支持  */
 #include <linux/cpuidle.h>
 #endif
 
@@ -1235,8 +1235,23 @@
 };
 
 #define HMP_DATA_SYSFS_MAX 8
-
-struct hmp_data_struct {
+/*
+ *  hmp_domains
+ *  up_threshold
+ *  down_threshold
+ *  #ifdef CONFIG_HMP_VARIABLE_SCALE
+ *  load_avg_period_ms              default(LOAD_AVG_PERIOD)
+ *  #endif
+ *  #ifdef CONFIG_HMP_FREQUENCY_INVARIANT_SCALE
+ *  frequency-invariant scaling     default(ON)
+ *  #endif
+ *  #ifdef CONFIG_SCHED_HMP_LITTLE_PACKING
+ *  packing_enable                  default(ON)
+ *  packing_limit                   default(hmp_full_threshold)
+ *  #endif
+ *  hmp
+ * */
+struct hmp_data_struct {            /*  sysfs 文件系统的操作接口    */
 #ifdef CONFIG_HMP_FREQUENCY_INVARIANT_SCALE
 	int freqinvar_load_scale_enabled;
 #endif
@@ -3649,7 +3664,12 @@
 }
 #endif
 
-/* Setup hmp_domains */
+/* Setup hmp_domains
+ *
+ * 调用关系
+ * init_sched_fair_class( )
+ *  ->  hmp_cpu_mask_setup( )
+ * */
 static int __init hmp_cpu_mask_setup(void)
 {
 	char buf[64];
@@ -3659,7 +3679,8 @@
 
 	pr_debug("Initializing HMP scheduler:\n");
 
-	/* Initialize hmp_domains using platform code */
+	/* Initialize hmp_domains using platform code
+     * see arch/arm[64]/kernel/topology.c   */
 	arch_get_hmp_domains(&hmp_domains);
 	if (list_empty(&hmp_domains)) {
 		pr_debug("HMP domain list is empty!\n");
@@ -3720,7 +3741,20 @@
 static inline struct hmp_domain *hmp_slower_domain(int cpu);
 static inline struct hmp_domain *hmp_faster_domain(int cpu);
 
-/* must hold runqueue lock for queue se is currently on */
+/* must hold runqueue lock for queue se is currently on
+ * 查找并返回CPU(target_cpu)上最繁忙的进程,
+ *
+ * 参数描述
+ * se           该 CPU 的当前进程curr的调度实体
+ * target_cpu   该 CPU 的编号, 如果传入-1, 则表示目标运行的cpu为大核调度域中任何一个合适的大核
+ *                             如果传入>0, 则表示任务将要迁移到的目标大核cpu
+ *
+ * 返回值
+ *  如果调度实体 se 所处的 CPU 是大核, 则直接返回  se
+ *  如果target_cpu > 0, 但是却不在大核的调度域中, 即该目标 CPU 是小核, 则返回NULL
+ *  其他情况参数正确且合法(se为小核上的某个调度实体, target_cpu 为-1或者某个大核),
+ *  则返回se所在的CPU上负载最大的那个调度实体 max_se
+ * */
 static struct sched_entity *hmp_get_heaviest_task(
 				struct sched_entity *se, int target_cpu)
 {
@@ -3730,24 +3764,27 @@
 	const struct cpumask *hmp_target_mask = NULL;
 	struct hmp_domain *hmp;
 
-	if (hmp_cpu_is_fastest(cpu_of(se->cfs_rq->rq)))
-		return max_se;
+	if (hmp_cpu_is_fastest(cpu_of(se->cfs_rq->rq))) /*  判断该 CPU 是否处于大核 CPU 的调度域中  */
+		return max_se;                              /*  如果是则直接返回当前进程的调度实体      */
 
 	hmp = hmp_faster_domain(cpu_of(se->cfs_rq->rq));
-	hmp_target_mask = &hmp->cpus;
-	if (target_cpu >= 0) {
+	hmp_target_mask = &hmp->cpus;                   /*  指向大核调度域中cpumask位图             */
+	if (target_cpu >= 0) {                          /*  如果参数target_cpu传入的是实际的CPU编号 */
 		/* idle_balance gets run on a CPU while
 		 * it is in the middle of being hotplugged
 		 * out. Bail early in that case.
 		 */
-		if(!cpumask_test_cpu(target_cpu, hmp_target_mask))
-			return NULL;
-		hmp_target_mask = cpumask_of(target_cpu);
+		if(!cpumask_test_cpu(target_cpu, hmp_target_mask))  /*  判断target_cpu是否在大核的调度域内  */
+			return NULL;                                    /*  如果指定的target_cpu不是大核,
+                                                                则当前操作为希望从一个小核上返回一个最繁忙的进程,
+                                                                却要把该进程放到另外一个小核target_cpu上, 返回NULL    */
+		hmp_target_mask = cpumask_of(target_cpu);           /*  设置mask信息为指定的target_cpu的mask信息    */
 	}
-	/* The currently running task is not on the runqueue */
+	/* The currently running task is not on the runqueue
+     * curr 进程是不在 CPU 的运行队列里面的 */
 	se = __pick_first_entity(cfs_rq_of(se));
 
-	while (num_tasks && se) {
+	while (num_tasks && se) {   /*  从当前CPU 的红黑树中找出负载最大的那个调度实体max_se    */
 		if (entity_is_task(se) &&
 			se->avg.load_avg_ratio > max_ratio &&
 			cpumask_intersects(hmp_target_mask,
@@ -3758,9 +3795,22 @@
 		se = __pick_next_entity(se);
 		num_tasks--;
 	}
+
 	return max_se;
 }
 
+/*  hmp_get_lightest_task()函数和 hmp_get_heaviest_task()函数类似,
+ *  返回 se 调度实体对应的运行队列中任务最轻的调度实体 min_se
+ *
+ *  参数
+ *      se              调度实体指示了待处理的调度实体, 其所在的运行队列 和 CPU
+ *      migrate_down    控制变量, 传入1, 表示检查是否可以进行向下迁移(将任务从大核迁移到小核)
+ *
+ *  调用关系
+ *      run_rebalance_domains( )
+ *          ->  hmp_force_up_migration( )
+ *              ->  hmp_get_lightest_task( )
+ * */
 static struct sched_entity *hmp_get_lightest_task(
 				struct sched_entity *se, int migrate_down)
 {
@@ -3769,9 +3819,9 @@
 	unsigned long int min_ratio = se->avg.load_avg_ratio;
 	const struct cpumask *hmp_target_mask = NULL;
 
-	if (migrate_down) {
+	if (migrate_down) {         /*  进行向下迁移, 将任务从大核迁移到小核    */
 		struct hmp_domain *hmp;
-		if (hmp_cpu_is_slowest(cpu_of(se->cfs_rq->rq)))
+		if (hmp_cpu_is_slowest(cpu_of(se->cfs_rq->rq))) /*  检查当前se所在的cpu是不是大核, 如果不是, 则直接返回 min_se = se   */
 			return min_se;
 		hmp = hmp_slower_domain(cpu_of(se->cfs_rq->rq));
 		hmp_target_mask = &hmp->cpus;
@@ -3779,7 +3829,7 @@
 	/* The currently running task is not on the runqueue */
 	se = __pick_first_entity(cfs_rq_of(se));
 
-	while (num_tasks && se) {
+	while (num_tasks && se) {               /*  从 se 所在 CPU 的任务队列上找到那个负载最小的进程 */
 		if (entity_is_task(se) &&
 			(se->avg.load_avg_ratio < min_ratio &&
 			hmp_target_mask &&
@@ -3819,7 +3869,13 @@
 unsigned int hmp_next_down_threshold = 4096;
 
 #ifdef CONFIG_SCHED_HMP_LITTLE_PACKING
-/*
+/* 小任务封包补丁, 将负载小于NICE_0 80% 的进程, 看做是小任务
+ * 将这些小任务打包成一个任务来看待, 他们共享负载和 CPU 频率
+ * 可以查看文档 Documentation/arm/small_task_packing.txt
+ * 如果系统中小任务比较多, 那么会将这些小任务进行封包调整, 迁移到一个小核 CPU 上
+ * 直到该核上所有运行的小任务的总负载达到了 /sys/kernel/hmp/packing_limit
+ * 这些小任务就被封装成了一个任务包
+ *
  * Set the default packing threshold to try to keep little
  * CPUs at no more than 80% of their maximum frequency if only
  * packing a small number of small tasks. Bigger tasks will
@@ -4244,6 +4300,22 @@
  *   + if all CPUs are equally loaded or idle and the times are
  *     all the same, the first in the set will be used
  *   + if affinity is not set, cpu_online_mask is used
+ *
+ *   参数
+ *   hmpd       HMP调度域, 一般来说传入的是大核的调度域
+ *   min_cpu    是一个指针变量用来传递结果给调用者
+ *   affinify   是另外一个cpumask位图, 在我们上下文中是刚才讨论的进程可以运行的 CPU 位图,
+ *              一般来说进程通常都运行在所有的CPU上运行
+ *
+ *   返回值
+ *   0      返回0, 表示找到了空闲的CPU, 并用 min_cpu 返回找到的 cpu 的编号
+ *   1023   返回1023, 表示该调度域没有空闲CPU也即是都在繁忙中
+ *
+ *   调用关系
+ *   run_rebalance_domains( )
+ *      ->  hmp_force_up_migration( )
+ *          ->  hmp_up_migration( )
+ *              -> hmp_domain_min_load
  */
 static inline unsigned int hmp_domain_min_load(struct hmp_domain *hmpd,
 						int *min_cpu, struct cpumask *affinity)
@@ -4260,27 +4332,32 @@
 	 * only look at CPUs allowed if specified,
 	 * otherwise look at all online CPUs in the
 	 * right HMP domain
+     *
+     * 检查hmpd 调度域上 cpumask 和 affinity 位图
 	 */
 	cpumask_and(&temp_cpumask, &hmpd->cpus, affinity ? affinity : cpu_online_mask);
 
-	for_each_cpu_mask(cpu, temp_cpumask) {
-		avg = &cpu_rq(cpu)->avg;
+	for_each_cpu_mask(cpu, temp_cpumask) {  /*  遍历 temp_cpumask 位图上的所有 CPU      */
+		avg = &cpu_rq(cpu)->avg;            /*  获取当前检查的 cpu 上运行队列的平均负载 */
 		/* used for both up and down migration */
 		curr_last_migration = avg->hmp_last_up_migration ?
 			avg->hmp_last_up_migration : avg->hmp_last_down_migration;
 
-		contrib = avg->load_avg_ratio;
+		contrib = avg->load_avg_ratio;      /*  获取平均负载信息 avg->load_avg_ratio    */
 		/*
 		 * Consider a runqueue completely busy if there is any load
 		 * on it. Definitely not the best for overall fairness, but
 		 * does well in typical Android use cases.
 		 */
-		if (contrib)
-			contrib = 1023;
+		if (contrib)                        /*  如果当前 cpu 上有负载(load_avg_ratio)   */
+			contrib = 1023;                 /*  那么 contrib 统统设置为 1023,
+            为何这样做呢?   因为该函数的目的就是找一个空闲CPU, 如果当前CPU有负载, 说明不空闲,
+            因此统一设置为 1023, 仅仅是为了表示该CPU不是空闲而已
+            同时一趟遍历下来, 如果没有空闲CPU, 则最小负载值值都是 1023  */
 
 		if ((contrib < min_runnable_load) ||
-			(contrib == min_runnable_load &&
-			 curr_last_migration < min_target_last_migration)) {
+			(contrib == min_runnable_load &&                        /*  如果有多个 CPU 的 contrib 值相同            */
+			 curr_last_migration < min_target_last_migration)) {    /*  那么选择该调度域中最近一个发生过迁移的CPU   */
 			/*
 			 * if the load is the same target the CPU with
 			 * the longest time since a migration.
@@ -4316,37 +4393,50 @@
 	return scale_load(starvation);
 }
 
+/*  为(大核上)负载最轻的进程调度实体 se 选择一个合适的迁移目标CPU(小核)
+ *
+ *
+ *  调用关系
+ *      run_rebalance_domains( )
+ *          ->  hmp_force_up_migration( )
+ *              ->  hmp_offload_down( )
+ *  */
 static inline unsigned int hmp_offload_down(int cpu, struct sched_entity *se)
 {
 	int min_usage;
 	int dest_cpu = NR_CPUS;
 
-	if (hmp_cpu_is_slowest(cpu))
+	if (hmp_cpu_is_slowest(cpu))    /*  如果当前CPU就是一个小核, 则无需迁移, */
 		return NR_CPUS;
 
-	/* Is there an idle CPU in the current domain */
+	/* Is there an idle CPU in the current domain
+     * 查找当前 cpu 调度域(大核)是否有空闲 CPU  */
 	min_usage = hmp_domain_min_load(hmp_cpu_domain(cpu), NULL, NULL);
-	if (min_usage == 0) {
+	if (min_usage == 0) {           /*  如果大核中有空闲的 CPU, 则也不做迁移    */
 		trace_sched_hmp_offload_abort(cpu, min_usage, "load");
 		return NR_CPUS;
 	}
 
 	/* Is the task alone on the cpu? */
-	if (cpu_rq(cpu)->cfs.h_nr_running < 2) {
+	if (cpu_rq(cpu)->cfs.h_nr_running < 2) {    /*  如果该 CPU 的运行队列中正在运行的进程只有一个或者没有, 那么也不需要迁移 */
 		trace_sched_hmp_offload_abort(cpu,
 			cpu_rq(cpu)->cfs.h_nr_running, "nr_running");
 		return NR_CPUS;
 	}
 
-	/* Is the task actually starving? */
+	/* Is the task actually starving? 判断当前进程是否饥饿  */
 	/* >=25% ratio running/runnable = starving */
-	if (hmp_task_starvation(se) > 768) {
+	if (hmp_task_starvation(se) > 768) {    /*  当starving > 75% 时说明该进程一直渴望获得更多的 CPU 时间, 这样的进程也不适合迁移    */
 		trace_sched_hmp_offload_abort(cpu, hmp_task_starvation(se),
 			"starvation");
 		return NR_CPUS;
 	}
 
-	/* Does the slower domain have any idle CPUs? */
+	/* Does the slower domain have any idle CPUs?
+     * 检查小核的调度域中是否有空闲的CPU
+     * 如果有的话返回该空闲 CPU,
+     * 如果没有的话返回 NR_CPUS, 说明没找到合适的CPU用做迁移的目的地
+     * */
 	min_usage = hmp_domain_min_load(hmp_slower_domain(cpu), &dest_cpu,
 			tsk_cpus_allowed(task_of(se)));
 
@@ -4369,6 +4459,13 @@
  * Returns the target CPU number, or the same CPU if no balancing is needed.
  *
  * preempt must be disabled.
+ *
+ * 在 HMP 调度器中对待新创建的进程会有特殊的处理
+ *
+ * 新创建的进程创建完成之后需要把进程添加到合适的运行队列中,
+ *
+ * 这个过程中会调用 select_task_rq( ) 函数来选择一个最合适新进程运行的 CPU
+ *
  */
 static int
 select_task_rq_fair(struct task_struct *p, int sd_flag, int wake_flags)
@@ -4385,7 +4482,7 @@
 
 #ifdef CONFIG_SCHED_HMP
 	/* always put non-kernel forking tasks on a big domain */
-	if (unlikely(sd_flag & SD_BALANCE_FORK) && hmp_task_should_forkboost(p)) {
+	if (unlikely(sd_flag & SD_BALANCE_FORK) && hmp_task_should_forkboost(p)) {  /*  对于新创建的进程并且该进程是用户进程    */
 		new_cpu = hmp_select_faster_cpu(p, prev_cpu);
 		if (new_cpu != NR_CPUS) {
 			hmp_next_up_delay(&p->se, new_cpu);
@@ -4882,7 +4979,7 @@
  *
  * The adjacency matrix of the resulting graph is given by:
  *
- *             log_2 n     
+ *             log_2 n
  *   A_i,j = \Union     (i % 2^k == 0) && i / 2^(k+1) == j / 2^(k+1)  (6)
  *             k = 0
  *
@@ -4928,7 +5025,7 @@
  *
  * [XXX write more on how we solve this.. _after_ merging pjt's patches that
  *      rewrite all of this once again.]
- */ 
+ */
 
 static unsigned long __read_mostly max_load_balance_interval = HZ/10;
 
@@ -5498,7 +5595,7 @@
 		/*
 		 * !SD_OVERLAP domains can assume that child groups
 		 * span the current group.
-		 */ 
+		 */
 
 		group = child->groups;
 		do {
@@ -6915,6 +7012,19 @@
 #endif
 
 #ifdef CONFIG_SCHED_HMP
+/*  判断进程实体 se 的平均负载是否高于 hmp_up_threshold 这个阀值
+ *  hmp_up_threshold 也是一个过滤作用
+ *  目前 HMP负载均衡调度器有几个负载
+ *
+ *  #ifdef CONFIG_SCHED_HMP_PRIO_FILTER
+ *  一个是优先级            hmp_up_prio, 优先级值高于hmp_up_prio(即优先级较低)的进程无需从小核迁移到大核
+ *  #endif                  该阀值由 CONFIG_SCHED_HMP_PRIO_FILTER 宏开启
+ *
+ *  一个是负载              hmp_up_threshold,   只有负载高于 hmp_up_threshold 的进程才需要迁移
+ *
+ *  一个是迁移的间隔        hmp_next_up_threshold,  只有上次迁移距离当前时间的间隔大于hmp_next_up_threshold 的进程才可以进行迁移
+ *                          该阀值避免进程被迁移来迁移去
+ *  */
 static unsigned int hmp_task_eligible_for_up_migration(struct sched_entity *se)
 {
 	/* below hmp_up_threshold, never eligible */
@@ -6923,26 +7033,59 @@
 	return 1;
 }
 
-/* Check if task should migrate to a faster cpu */
+/* Check if task should migrate to a faster cpu
+ * 检查 cpu 上的调度实体 se 是否需要迁移到大核上
+ *
+ * 调用关系
+ * run_rebalance_domains( )
+ *  ->  hmp_force_up_migration( )
+ *      ->  hmp_up_migration( )
+ *
+ * 返回值
+ *
+ *  如果 se 本来就是在大核上运行, 则无需进行向上迁移, return 0
+ *
+ *  如果开启了CONFIG_SCHED_HMP_PRIO_FILTER宏,
+ *  而se->prio > hmp_up_prio, 即 se 的优先级过于低, 不适宜向上迁移,
+ *  这点是符合现实情况的, 低优先级的进程无关紧要, 用户也不会在意其更快的完成和响应,
+ *  自然没必要需要迁移到大核上去获得更高的性能, return 0
+ *
+ *  该进程上一次迁移离现在的时间间隔小于 hmp_next_up_threshold 阀值的也不需要迁移, 避免被迁移来迁移去, return 0
+ *
+ *  其他情况, 如果进程满足向上迁移的需求, 则从大核的调度域中找到一个空闲的CPU
+ * */
 static unsigned int hmp_up_migration(int cpu, int *target_cpu, struct sched_entity *se)
 {
 	struct task_struct *p = task_of(se);
 	int temp_target_cpu;
 	u64 now;
 
-	if (hmp_cpu_is_fastest(cpu))
-		return 0;
+	if (hmp_cpu_is_fastest(cpu))        /*  首先判断 se 原来所运行的 cpu 是否在大核的调度域  */
+		return 0;                       /*  如果已经在大核的调度域内, 则没必要进行迁移繁忙的进程　se 到大核 target_cpu 上   */
 
 #ifdef CONFIG_SCHED_HMP_PRIO_FILTER
-	/* Filter by task priority */
+	/* Filter by task priority
+     * hmp_up_prio 用于过滤优先级高于该值的进程,
+     * 如果待迁移进程 p 优先级大于 hmp_up_prio ,
+     * 那么也没必要迁移到大核 CPU 上
+     *
+     * 这个要打开 CONFIG_SCHED_HMP_PRIO_FILTER  这个宏才能开始此功能,
+     * 另外注意优先级的数值是越低优先级越高,
+     * 因此此功能类似于如果任务优先级比较低,
+     * 可以设置一个阀值 hmp_up_prio,
+     * 优先级低于阀值的进程即使再繁重我们也不需要对他进行迁移,
+     * 从而保证高优先级进行优先得到响应和迁移   */
 	if (p->prio >= hmp_up_prio)
 		return 0;
 #endif
-	if (!hmp_task_eligible_for_up_migration(se))
+	if (!hmp_task_eligible_for_up_migration(se))    /*  判断该进程实体se的平均负载是否高于 hmp_up_threshold 这个阀值   */
 		return 0;
 
 	/* Let the task load settle before doing another up migration */
 	/* hack - always use clock from first online CPU */
+    /*  迁移时间上的过滤,
+     *  该进程上一次迁移离现在的时间间隔小于 hmp_next_up_threshold 阀值的也不需要迁移,
+     *  从而避免进程被迁移来迁移去  */
 	now = cpu_rq(cpumask_first(cpu_online_mask))->clock_task;
 	if (((now - se->avg.hmp_last_up_migration) >> 10)
 					< hmp_next_up_threshold)
@@ -6951,24 +7094,28 @@
 	/* hmp_domain_min_load only returns 0 for an
 	 * idle CPU or 1023 for any partly-busy one.
 	 * Be explicit about requirement for an idle CPU.
+     *
+     * 查找大核调度域中是否有空闲的CPU
 	 */
 	if (hmp_domain_min_load(hmp_faster_domain(cpu), &temp_target_cpu,
-			tsk_cpus_allowed(p)) == 0 && temp_target_cpu != NR_CPUS) {
+			tsk_cpus_allowed(p)) == 0 && temp_target_cpu != NR_CPUS) {  /*  如果在大核调度域中找到了一个空闲的CPU, 即target_cpu */
 		if(target_cpu)
-			*target_cpu = temp_target_cpu;
-		return 1;
+			*target_cpu = temp_target_cpu;  /*  设置 target_cpu 为查找到的 CPU                              */
+		return 1;                           /*  返回1, 在大核调度域中发现了空闲的 CPU, 用 target_cpu 返回   */
 	}
 	return 0;
 }
 
-/* Check if task should migrate to a slower cpu */
+/* Check if task should migrate to a slower cpu
+ * 检查当前进程调度实体是否可以被迁移至一个小核
+ * */
 static unsigned int hmp_down_migration(int cpu, struct sched_entity *se)
 {
 	struct task_struct *p = task_of(se);
 	u64 now;
 
-	if (hmp_cpu_is_slowest(cpu)) {
-#ifdef CONFIG_SCHED_HMP_LITTLE_PACKING
+	if (hmp_cpu_is_slowest(cpu)) {          /*  如果当前调度实体所在的 CPU 已经是小核       */
+#ifdef CONFIG_SCHED_HMP_LITTLE_PACKING      /*  小任务封包补丁, 运行小任务在小核之间迁移    */
 		if(hmp_packing_enabled)
 			return 1;
 		else
@@ -7097,13 +7244,22 @@
  * Tailored on 'active_load_balance_cpu_stop' with slight
  * modification to locking and pre-transfer checks.  Note
  * rq->lock must be held before calling.
+ *
+ * 迁移源 CPU 是 for 循环遍历到的 CPU,  cpu_of(rq)
+ * 迁移进程是之前找到的那个负载比较轻的进程,    rq->migrate_task
+ * 迁移目的地 CPU 是在小核调度域中找到的空闲 CPU,   rq->push_cpu
+ *
+ * 调用关系
+ * run_rebalance_domains( )
+ *  ->  hmp_force_up_migration( )
+ *      ->  hmp_migrate_runnable_task( )
  */
 static void hmp_migrate_runnable_task(struct rq *rq)
 {
 	struct sched_domain *sd;
-	int src_cpu = cpu_of(rq);
+	int src_cpu = cpu_of(rq);                   /*  迁移的源cpu     */
 	struct rq *src_rq = rq;
-	int dst_cpu = rq->push_cpu;
+	int dst_cpu = rq->push_cpu;                 /*  迁移的目的cpu   */
 	struct rq *dst_rq = cpu_rq(dst_cpu);
 	struct task_struct *p = rq->migrate_task;
 	/*
@@ -7113,10 +7269,10 @@
 	if (src_rq->active_balance)
 		goto out;
 
-	if (src_rq->nr_running <= 1)
+	if (src_rq->nr_running <= 1)    /*  源 CPU 的运行队列上的任务数目 <= 1, 则不应该迁移    */
 		goto out;
 
-	if (task_rq(p) != src_rq)
+	if (task_rq(p) != src_rq)       /*  如果待迁移进程 p 并不在源 CPU (的任务队列)上, 则也不能迁移    */
 		goto out;
 	/*
 	 * Not sure if this applies here but one can never
@@ -7124,14 +7280,17 @@
 	 */
 	BUG_ON(src_rq == dst_rq);
 
-	double_lock_balance(src_rq, dst_rq);
+	double_lock_balance(src_rq, dst_rq);        /*  对源迁移任务队列src_rq 和 目的任务 dst_rq 加锁  */
 
 	rcu_read_lock();
 	for_each_domain(dst_cpu, sd) {
 		if (cpumask_test_cpu(src_cpu, sched_domain_span(sd)))
 			break;
 	}
-
+    /*  这里和内核默认的负载均衡调度器的 load_balance( ) 函数一样使用 struct lb_env 结构体来描述迁移信息
+     *  迁移的动作是 move_specific_task()函数
+     *
+     *  move_specific_task( ) 函数的实现和 load_balance( )函数里实现的类似  */
 	if (likely(sd)) {
 		struct lb_env env = {
 			.sd             = sd,
@@ -7161,6 +7320,10 @@
 /*
  * hmp_force_up_migration checks runqueues for tasks that need to
  * be actively migrated to a faster cpu.
+ *
+ * 调用关系
+ * run_rebalance_domains( )
+ *  ->  hmp_force_up_migration( )
  */
 static void hmp_force_up_migration(int this_cpu)
 {
@@ -7171,19 +7334,21 @@
 	unsigned int force, got_target;
 	struct task_struct *p;
 
+    /*  hmp_force_migration 是一个 HMP 定义的锁  */
 	if (!spin_trylock(&hmp_force_migration))
 		return;
+    /*  从头开始遍历 所有在线(活跃)的 CPU, 由cpu_online_mask 标识   */
 	for_each_online_cpu(cpu) {
 		force = 0;
 		got_target = 0;
-		target = cpu_rq(cpu);
-		raw_spin_lock_irqsave(&target->lock, flags);
-		curr = target->cfs.curr;
-		if (!curr || target->active_balance) {
+		target = cpu_rq(cpu);   /*  获取到 CPU 的运行队列   */
+		raw_spin_lock_irqsave(&target->lock, flags);    /*  对运行队列加锁  */
+		curr = target->cfs.curr;    /*  获取到 CPU 上当前的调度实体 */
+		if (!curr || target->active_balance) {  /*  如果当前CPU上正在做负载均衡, 则跳过该CPU    */
 			raw_spin_unlock_irqrestore(&target->lock, flags);
 			continue;
 		}
-		if (!entity_is_task(curr)) {
+		if (!entity_is_task(curr)) {    /*  如果当前运行的调度实体不是进程, 而是一个进程组, 则从中取出正在运行的进, 而是一个进程组, 则从中取出正在运行的进程程  */
 			struct cfs_rq *cfs_rq;
 
 			cfs_rq = group_cfs_rq(curr);
@@ -7192,35 +7357,90 @@
 				cfs_rq = group_cfs_rq(curr);
 			}
 		}
+        /*  任务迁移分为向上迁移和向下迁移,
+         *
+         *  向上迁移(hmp_up_migration)      -=> 将小核上负载最大且符合迁移要求的进程调度实体迁移至空闲的大核target_cpu
+         *  向下迁移(hmp_down_migration)    -=> 将大核上负载最小且符合迁移要求的进程调度实体迁移至空闲的小核target_cpu
+         *
+         *  首先检查是否可以进行向上迁移
+         *
+         *  如果当前遍历到的CPU核是小核, 则
+         *      hmp_get_heaviest_task   从该小核CPU上找到一个负载最大的进程调度实体curr
+         *      hmp_up_migration        判断负载最大的进程是否满足迁移到大核上所需的条件
+         *                              如果满足迁移的要求, 而当前所有的大核中也有空闲的大核
+         *                              则返回 1, 并用target_cpu 标记空闲的大核
+         *      下面通知内核可以将任务的向上迁移
+         *      cpu_rq(target_cpu)->wake_for_idle_pull = 1; 设置将要迁移的目标 CPU(target_cpu) 运行队列上的 wake_for_idle_pull 标志位
+         *      smp_send_reschedule(target_cpu);            发送一个IPI_RESCHEDULE 的 IPI 中断给 target_cpu
+         *
+         *  */
 		orig = curr;
-		curr = hmp_get_heaviest_task(curr, -1);
-		if (!curr) {
+		curr = hmp_get_heaviest_task(curr, -1); /*  从当前 CPU(小核) 中找到负载 se->avg.load_avg_ratio 最大(即最繁忙)的那个进程*/
+		if (!curr) {                            /*  没有需要迁移的进程*/
 			raw_spin_unlock_irqrestore(&target->lock, flags);
 			continue;
 		}
-		p = task_of(curr);
-		if (hmp_up_migration(cpu, &target_cpu, curr)) {
-			cpu_rq(target_cpu)->wake_for_idle_pull = 1;
+		p = task_of(curr);                      /*  获取到找到的大负载进行的 task_struct 结构 */
+		if (hmp_up_migration(cpu, &target_cpu, curr)) {         /*  判断刚才取得的最大负载的调度实体 curr 是否需要迁移到大核 CPU 上, 如果需要则找到大核中一个空闲的 CPU(target_cpu)  */
+			cpu_rq(target_cpu)->wake_for_idle_pull = 1;         /*  设置将要迁移的目标 CPU(target_cpu) 运行队列上的 wake_for_idle_pull 标志位  */
 			raw_spin_unlock_irqrestore(&target->lock, flags);
 			spin_unlock(&hmp_force_migration);
-			smp_send_reschedule(target_cpu);
+			smp_send_reschedule(target_cpu);                    /*  发送一个IPI_RESCHEDULE 的 IPI 中断给 target_cpu */
 			return;
 		}
-		if (!got_target) {
+		/*  刚才那个 CPU 真是小幸运,
+         *      正好它是小核上的 CPU
+         *      并且有合适迁移到大核上的进程(负载大于阀值, 且近期未发生迁移, 进程优先级也满足阀值要求)
+         *      最重要的是大核调度域上有空闲的 CPU,
+         *  这叫作无巧不成书.
+         *
+         *  我们下面看看没那么好运气的其他 CPU 的情况, 一般来说有如下几种情况
+         *      hmp_up_migration( )返回了 0
+         *          一种是调度实体curr需要向上迁移, 但是大核的调度域内没有空闲的的大核CPU
+         *          另外一种是调度实体不需要迁移(不满足阀值要求, 或者curr本身就在大核上)
+         *
+         *  我们首先考虑curr本身就在大核上运行的情况其他的情况,
+         *  curr运行在大核上时hmp_get_heaviest_task直接返回了curr(此时orig == curr)
+         *  而hmp_up_migration( )在判断进程在大核上运行时也直接返回了0,
+         */
+
+        /*  任务迁移分为向上迁移和向下迁移,
+         *
+         *  向上迁移(hmp_up_migration)      -=> 将小核上负载最大且符合迁移要求的进程调度实体迁移至空闲的大核target_cpu
+         *  向下迁移(hmp_down_migration)    -=> 将大核上负载最小且符合迁移要求的进程调度实体迁移至空闲的小核target_cpu
+         *
+         *  接着检查是否可以进行向下迁移
+         *
+         *  如果当前遍历到的CPU核是大核, 则
+         *      hmp_get_lightest_task   从该大核 CPU 上找到一个负载最小的进程调度实体 curr
+         *      hmp_offload_down        判断负载最小的进程是否满足迁移到小核上所需的条件
+         *                              如果满足迁移的要求, 而当前所有的小核中也有空闲的小核
+         *                              则返回可以迁移的空闲的小核
+         *
+         *      接着完善迁移信息, 填充迁移源 CPU 的任务队列 rq(target) 的信息,
+         *      包括如下信息    :
+         *          迁移目标cpu(target->push_cpu)
+         *          待迁移进程target->migrate_task = p;
+         *
+         *      最后内核完成任务的向下迁移
+         *          如果待迁移的任务没在运行, 直接调用 hmp_migrate_runnable_task(target)完成任务迁移
+         *          如果带迁移的任务在运行, 则调用 stop_one_cpu_nowait(cpu_of(target) 暂停迁移源 CPU 后, 强行进行迁移
+         */
+        if (!got_target) {                                      /*  如果此时没有*/
 			/*
 			 * For now we just check the currently running task.
 			 * Selecting the lightest task for offloading will
 			 * require extensive book keeping.
 			 */
-			curr = hmp_get_lightest_task(orig, 1);
+			curr = hmp_get_lightest_task(orig, 1);          /*  返回 orig 调度实体对应的运行队列中任务最轻的调度实体min_se  */
 			p = task_of(curr);
-			target->push_cpu = hmp_offload_down(cpu, curr);
-			if (target->push_cpu < NR_CPUS) {
+			target->push_cpu = hmp_offload_down(cpu, curr); /*  查询刚才找到的最轻负载的进程能迁移到哪个 CPU上去, 返回迁移目标target->push_cpu  */
+			if (target->push_cpu < NR_CPUS) {               /*  如果返回值是NR_CPUS, 则表示没有找到合适的迁移目标CPU    */
 				get_task_struct(p);
 				target->migrate_task = p;
 				got_target = 1;
 				trace_sched_hmp_migrate(p, target->push_cpu, HMP_MIGRATE_OFFLOAD);
-				hmp_next_down_delay(&p->se, target->push_cpu);
+				hmp_next_down_delay(&p->se, target->push_cpu);      /*  更新调度实体的hmp_last_down_migration和hmp_last_up_migration 记录为现在时刻的时间   */
 			}
 		}
 		/*
@@ -7229,21 +7449,22 @@
 		 * CPU stopper take care of it.
 		 */
 		if (got_target) {
-			if (!task_running(target, p)) {
+			if (!task_running(target, p)) {     /*  如果要迁移的进程p没有正在运行, 即p->on_cpu == 0, 则可以进行迁移 */
 				trace_sched_hmp_migrate_force_running(p, 0);
-				hmp_migrate_runnable_task(target);
-			} else {
-				target->active_balance = 1;
-				force = 1;
+				hmp_migrate_runnable_task(target);  /*  完成任务迁移*/
+			} else {                            /*  否则待迁移的进程如果正在运行            */
+				target->active_balance = 1;     /*  设置 target 运行队列的 avtive_balance   */
+				force = 1;                      /*  设置强制迁移标示为1                     */
 			}
 		}
 
 		raw_spin_unlock_irqrestore(&target->lock, flags);
 
-		if (force)
+		if (force)              /*  依照前面所述, 待迁移的进程 p 正在运行中, 则 force被置为 1 */
 			stop_one_cpu_nowait(cpu_of(target),
 				hmp_active_task_migration_cpu_stop,
-				target, &target->active_balance_work);
+				target, &target->active_balance_work);  /*  暂停迁移源 CPU 后, 强行进行迁移 */
+        /*  自此我们了解到, 如果*/
 	}
 	spin_unlock(&hmp_force_migration);
 }
@@ -7264,15 +7485,16 @@
 	unsigned int force = 0;
 	struct task_struct *p = NULL;
 
-	if (!hmp_cpu_is_slowest(this_cpu))
-		hmp_domain = hmp_slower_domain(this_cpu);
+	if (!hmp_cpu_is_slowest(this_cpu))      /*  检查当前 CPU 是不是大核 */
+		hmp_domain = hmp_slower_domain(this_cpu);   /*  如果是大核(不是小核), 则取出小核的 domain 结构*/
 	if (!hmp_domain)
 		return 0;
 
-	if (!spin_trylock(&hmp_force_migration))
+	if (!spin_trylock(&hmp_force_migration))    /*  加锁    */
 		return 0;
 
-	/* first select a task */
+	/* first select a task
+     * for循环遍历小核调度域上的所有 CPU, 找出该 CPU 的运行队列中负载最重的进程 curr    */
 	for_each_cpu(cpu, &hmp_domain->cpus) {
 		rq = cpu_rq(cpu);
 		raw_spin_lock_irqsave(&rq->lock, flags);
@@ -7294,11 +7516,11 @@
 			}
 		}
 		orig = curr;
-		curr = hmp_get_heaviest_task(curr, this_cpu);
+		curr = hmp_get_heaviest_task(curr, this_cpu);   /*  从当前CPU中找到负载最大(即最繁忙)的那个进程 */
 		/* check if heaviest eligible task on this
 		 * CPU is heavier than previous task
 		 */
-		if (curr && hmp_task_eligible_for_up_migration(curr) &&
+		if (curr && hmp_task_eligible_for_up_migration(curr) && /*  先判断这个负载重的进程是否合适迁移到大核 CPU 上(比较其负载是否大于阀值)   */
 			curr->avg.load_avg_ratio > ratio &&
 			cpumask_test_cpu(this_cpu,
 					tsk_cpus_allowed(task_of(curr)))) {
@@ -7312,33 +7534,37 @@
 	if (!p)
 		goto done;
 
-	/* now we have a candidate */
+	/* now we have a candidate
+     * 迁移进程 migrate_task    :   是刚才找到的 p = task_of(curr) 进程
+     * 迁移源 CPU               :   迁移进程对应的 CPU
+     * 迁移目的地 CPU           :   当前 CPU, 当前 CPU 是大核调度域中的一个
+     * */
 	raw_spin_lock_irqsave(&target->lock, flags);
 	if (!target->active_balance && task_rq(p) == target) {
 		get_task_struct(p);
-		target->push_cpu = this_cpu;
-		target->migrate_task = p;
+		target->push_cpu = this_cpu;        /*  迁移的目的 CPU  */
+		target->migrate_task = p;           /*  待迁移的进程    */
 		trace_sched_hmp_migrate(p, target->push_cpu, HMP_MIGRATE_IDLE_PULL);
-		hmp_next_up_delay(&p->se, target->push_cpu);
+		hmp_next_up_delay(&p->se, target->push_cpu);    /*  更新当前迁移的时间为 now    */
 		/*
 		 * if the task isn't running move it right away.
 		 * Otherwise setup the active_balance mechanic and let
 		 * the CPU stopper do its job.
 		 */
-		if (!task_running(target, p)) {
+		if (!task_running(target, p)) {                     /*  如果待迁移的进程不在运行    */
 			trace_sched_hmp_migrate_idle_running(p, 0);
-			hmp_migrate_runnable_task(target);
+			hmp_migrate_runnable_task(target);              /*  直接对进程进行迁移          */
 		} else {
 			target->active_balance = 1;
-			force = 1;
+			force = 1;                                      /*  否则设置强制迁移标识 force 为 1 */
 		}
 	}
 	raw_spin_unlock_irqrestore(&target->lock, flags);
 
 	if (force) {
 		/* start timer to keep us awake */
-		hmp_cpu_keepalive_trigger();
-		stop_one_cpu_nowait(cpu_of(target),
+		hmp_cpu_keepalive_trigger();                    /*  为大核设置保活监控定时器  */
+		stop_one_cpu_nowait(cpu_of(target),             /*  如果迁移进程正在运行, 那么和之前一样, 调用 stop_one_cpu_nowait( ) 函数强行迁移  */
 			hmp_active_task_migration_cpu_stop,
 			target, &target->active_balance_work);
 	}
@@ -7362,10 +7588,18 @@
 						CPU_IDLE : CPU_NOT_IDLE;
 
 #ifdef CONFIG_SCHED_HMP
-	/* shortcut for hmp idle pull wakeups */
+	/* shortcut for hmp idle pull wakeups
+     *
+     * 首先检查当前CPU运行队列的wake_for_idle_pull 标识
+     * 该标志位是说
+     *  有一个小核调度域上的比较繁忙的进程需要被迁移到大核上
+     *  而大核的调度域上刚好有一个空闲的 CPU
+     *
+     *  那么这样正好可以适合把该进程迁移到大核的空闲CPU上
+     * */
 	if (unlikely(this_rq->wake_for_idle_pull)) {
-		this_rq->wake_for_idle_pull = 0;
-		if (hmp_idle_pull(this_cpu)) {
+		this_rq->wake_for_idle_pull = 0;    /*  清楚大核上的 wake_for_idle_pull 标示 */
+		if (hmp_idle_pull(this_cpu)) {      /*  idle 的大核 CPU(this_cpu) 开始 pull 进程从别的 CPU 上   */
 			/* break out unless running nohz idle as well */
 			if (idle != CPU_IDLE)
 				return;
@@ -7878,7 +8112,9 @@
 __init void init_sched_fair_class(void)
 {
 #ifdef CONFIG_SMP
-	open_softirq(SCHED_SOFTIRQ, run_rebalance_domains);
+    /*  和内核中默认的负载均衡调度器一样需要注册一个软中断softirq,
+     *  回调函数是run_rebalance_domains( ) */
+    open_softirq(SCHED_SOFTIRQ, run_rebalance_domains);
 
 #ifdef CONFIG_NO_HZ_COMMON
 	nohz.next_balance = jiffies;
@@ -7887,7 +8123,15 @@
 #endif
 
 #ifdef CONFIG_SCHED_HMP
-	hmp_cpu_mask_setup();
+    /*  另外一个就是建立 HMP 的 CPU 拓扑关系(CPU TOPOLOBY)
+     *  [CPU 的拓扑结构可以参见, include/linux/topology.h 或者具体体系结构的实现]
+     *  HMP 调度器重新定义了 domain 的实现,
+     *  定义了 struct hmp_domain 数据结构(include/linux/sched.h)
+     *  该结构比较简单, cpus 和 possible_cpus 两个 cpumask 变量以及一个链表节点.
+     *  hmp_cpu_domain 是定义为 pre-CPU 变量,
+     *  即每个 CPU 有一个 struct hmp_domain 数据结构,
+     *  另外还定义了一个全局的链表 hmp_domains */
+    hmp_cpu_mask_setup();
 #endif
 #endif /* SMP */
 
diff -Naur linux-linaro-stable-3.10.100-2016.03/kernel/sched/sched.h ../big-LITTLE/GitHub/3.10/kernel/sched/sched.h
--- linux-linaro-stable-3.10.100-2016.03/kernel/sched/sched.h	2016-03-31 16:31:10.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/kernel/sched/sched.h	2016-11-30 16:24:43.817858362 +0800
@@ -465,8 +465,8 @@
 	int push_cpu;
 	struct cpu_stop_work active_balance_work;
 #ifdef CONFIG_SCHED_HMP
-	struct task_struct *migrate_task;
-	int wake_for_idle_pull;
+	struct task_struct *migrate_task;       /*  当前 CPU 运行队列 rq 上, 待迁移的进程   */
+	int wake_for_idle_pull;                 /*  当 发生 向上迁移(up migrate) 时, 通知大核 CPU 苏醒wakeup执行迁移的标识  */
 #endif
 	/* cpu of this runqueue: */
 	int cpu;
diff -Naur linux-linaro-stable-3.10.100-2016.03/.mailmap ../big-LITTLE/GitHub/3.10/.mailmap
--- linux-linaro-stable-3.10.100-2016.03/.mailmap	2016-03-31 16:31:06.000000000 +0800
+++ ../big-LITTLE/GitHub/3.10/.mailmap	1970-01-01 08:00:00.000000000 +0800
@@ -1,118 +0,0 @@
-#
-# This list is used by git-shortlog to fix a few botched name translations
-# in the git archive, either because the author's full name was messed up
-# and/or not always written the same way, making contributions from the
-# same person appearing not to be so or badly displayed.
-#
-# repo-abbrev: /pub/scm/linux/kernel/git/
-#
-
-Aaron Durbin <adurbin@google.com>
-Adam Oldham <oldhamca@gmail.com>
-Adam Radford <aradford@gmail.com>
-Adrian Bunk <bunk@stusta.de>
-Alan Cox <alan@lxorguk.ukuu.org.uk>
-Alan Cox <root@hraefn.swansea.linux.org.uk>
-Aleksey Gorelov <aleksey_gorelov@phoenix.com>
-Al Viro <viro@ftp.linux.org.uk>
-Al Viro <viro@zenIV.linux.org.uk>
-Andreas Herrmann <aherrman@de.ibm.com>
-Andrew Morton <akpm@osdl.org>
-Andrew Vasquez <andrew.vasquez@qlogic.com>
-Andy Adamson <andros@citi.umich.edu>
-Archit Taneja <archit@ti.com>
-Arnaud Patard <arnaud.patard@rtp-net.org>
-Arnd Bergmann <arnd@arndb.de>
-Axel Dyks <xl@xlsigned.net>
-Axel Lin <axel.lin@gmail.com>
-Ben Gardner <bgardner@wabtec.com>
-Ben M Cahill <ben.m.cahill@intel.com>
-Björn Steinbrink <B.Steinbrink@gmx.de>
-Brian Avery <b.avery@hp.com>
-Brian King <brking@us.ibm.com>
-Christoph Hellwig <hch@lst.de>
-Corey Minyard <minyard@acm.org>
-Damian Hobson-Garcia <dhobsong@igel.co.jp>
-David Brownell <david-b@pacbell.net>
-David Woodhouse <dwmw2@shinybook.infradead.org>
-Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>
-Domen Puncer <domen@coderock.org>
-Douglas Gilbert <dougg@torque.net>
-Ed L. Cashin <ecashin@coraid.com>
-Evgeniy Polyakov <johnpol@2ka.mipt.ru>
-Felipe W Damasio <felipewd@terra.com.br>
-Felix Kuhling <fxkuehl@gmx.de>
-Felix Moeller <felix@derklecks.de>
-Filipe Lautert <filipe@icewall.org>
-Franck Bui-Huu <vagabon.xyz@gmail.com>
-Frank Zago <fzago@systemfabricworks.com>
-Greg Kroah-Hartman <greg@echidna.(none)>
-Greg Kroah-Hartman <gregkh@suse.de>
-Greg Kroah-Hartman <greg@kroah.com>
-Henk Vergonet <Henk.Vergonet@gmail.com>
-Henrik Kretzschmar <henne@nachtwindheim.de>
-Herbert Xu <herbert@gondor.apana.org.au>
-Jacob Shin <Jacob.Shin@amd.com>
-James Bottomley <jejb@mulgrave.(none)>
-James Bottomley <jejb@titanic.il.steeleye.com>
-James E Wilson <wilson@specifix.com>
-James Ketrenos <jketreno@io.(none)>
-Jean Tourrilhes <jt@hpl.hp.com>
-Jeff Garzik <jgarzik@pretzel.yyz.us>
-Jens Axboe <axboe@suse.de>
-Jens Osterkamp <Jens.Osterkamp@de.ibm.com>
-John Stultz <johnstul@us.ibm.com>
-Juha Yrjola <at solidboot.com>
-Juha Yrjola <juha.yrjola@nokia.com>
-Juha Yrjola <juha.yrjola@solidboot.com>
-Kay Sievers <kay.sievers@vrfy.org>
-Kenneth W Chen <kenneth.w.chen@intel.com>
-Koushik <raghavendra.koushik@neterion.com>
-Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
-Leonid I Ananiev <leonid.i.ananiev@intel.com>
-Linas Vepstas <linas@austin.ibm.com>
-Mark Brown <broonie@sirena.org.uk>
-Matthieu CASTET <castet.matthieu@free.fr>
-Mayuresh Janorkar <mayur@ti.com>
-Michael Buesch <m@bues.ch>
-Michel Dänzer <michel@tungstengraphics.com>
-Mitesh shah <mshah@teja.com>
-Morten Welinder <terra@gnome.org>
-Morten Welinder <welinder@anemone.rentec.com>
-Morten Welinder <welinder@darter.rentec.com>
-Morten Welinder <welinder@troll.com>
-Mythri P K <mythripk@ti.com>
-Nguyen Anh Quynh <aquynh@gmail.com>
-Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
-Patrick Mochel <mochel@digitalimplant.org>
-Peter A Jonsson <pj@ludd.ltu.se>
-Peter Oruba <peter@oruba.de>
-Peter Oruba <peter.oruba@amd.com>
-Praveen BP <praveenbp@ti.com>
-Rajesh Shah <rajesh.shah@intel.com>
-Ralf Baechle <ralf@linux-mips.org>
-Ralf Wildenhues <Ralf.Wildenhues@gmx.de>
-Rémi Denis-Courmont <rdenis@simphalempin.com>
-Rudolf Marek <R.Marek@sh.cvut.cz>
-Rui Saraiva <rmps@joel.ist.utl.pt>
-Sachin P Sant <ssant@in.ibm.com>
-Sam Ravnborg <sam@mars.ravnborg.org>
-Sascha Hauer <s.hauer@pengutronix.de>
-S.Çağlar Onur <caglar@pardus.org.tr>
-Simon Kelley <simon@thekelleys.org.uk>
-Stéphane Witzmann <stephane.witzmann@ubpmes.univ-bpclermont.fr>
-Stephen Hemminger <shemminger@osdl.org>
-Sumit Semwal <sumit.semwal@ti.com>
-Tejun Heo <htejun@gmail.com>
-Thomas Graf <tgraf@suug.ch>
-Tony Luck <tony.luck@intel.com>
-Tsuneo Yoshioka <Tsuneo.Yoshioka@f-secure.com>
-Uwe Kleine-König <ukleinek@informatik.uni-freiburg.de>
-Uwe Kleine-König <ukl@pengutronix.de>
-Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>
-Valdis Kletnieks <Valdis.Kletnieks@vt.edu>
-Viresh Kumar <viresh.linux@gmail.com> <viresh.kumar@st.com>
-Takashi YOSHII <takashi.yoshii.zj@renesas.com>
-Yusuke Goda <goda.yusuke@renesas.com>
-Gustavo Padovan <gustavo@las.ic.unicamp.br>
-Gustavo Padovan <padovan@profusion.mobi>
